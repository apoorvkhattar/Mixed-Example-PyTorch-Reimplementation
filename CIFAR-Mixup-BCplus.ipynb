{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions.beta as beta\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn.functional import relu, avg_pool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Preparation Arguments'''\n",
    "data_prep_from_scratch = True\n",
    "dataset = 'cifar10'\n",
    "path_dataset = './Data/CIFAR10/'\n",
    "\n",
    "'''Data Augmentation Method'''\n",
    "method = 'vhmixup'\n",
    "\n",
    "'''Optimization Arguments'''\n",
    "batch_size = 128\n",
    "train_epochs = 225\n",
    "\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "# Increase LR from 0.01 to 1.\n",
    "lr_scheduler_1_gamma = 10.0; milestones_1 = [400]\n",
    "# Lower LR from 1. to 0.01\n",
    "lr_scheduler_2_gamma = 0.1; milestones_2 = [32000, 48000, 70000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_prep_from_scratch and dataset == 'cifar100':\n",
    "    cifar100_train = unpickle(os.path.join(path_dataset, 'train'))\n",
    "    cifar100_test = unpickle(os.path.join(path_dataset, 'test'))\n",
    "\n",
    "    x_tr = torch.from_numpy(cifar100_train[b'data'].reshape((-1,32,32,3), order='F')).permute(0,2,1,3)\n",
    "    y_tr = torch.LongTensor(cifar100_train[b'fine_labels'])\n",
    "    x_te = torch.from_numpy(cifar100_test[b'data'].reshape((-1,32,32,3), order='F')).permute(0,2,1,3)\n",
    "    y_te = torch.LongTensor(cifar100_test[b'fine_labels'])\n",
    "\n",
    "    torch.save((x_tr, y_tr, x_te, y_te), os.path.join(path_dataset, '{}.pt'.format(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_prep_from_scratch and dataset == 'cifar10':\n",
    "    x_tr, y_tr = None, None\n",
    "    for b in range(5):\n",
    "        cifar10_train = unpickle(os.path.join(path_dataset, 'data_batch_{}'.format(b+1)))\n",
    "        \n",
    "        batch_img = torch.from_numpy(cifar10_train[b'data'].reshape((-1,32,32,3), order='F')).permute(0,2,1,3)\n",
    "        batch_label = torch.LongTensor(cifar10_train[b'labels'])\n",
    "        \n",
    "        if x_tr is None:\n",
    "            x_tr = batch_img\n",
    "            y_tr = batch_label\n",
    "        else:\n",
    "            x_tr = torch.cat((x_tr, batch_img), dim=0)\n",
    "            y_tr = torch.cat((y_tr, batch_label), dim=0)\n",
    "    \n",
    "    cifar10_test = unpickle(os.path.join(path_dataset, 'test_batch'))\n",
    "    x_te = torch.from_numpy(cifar10_test[b'data'].reshape((-1,32,32,3), order='F')).permute(0,2,1,3)\n",
    "    y_te = torch.LongTensor(cifar10_test[b'labels'])\n",
    "    \n",
    "    torch.save((x_tr, y_tr, x_te, y_te), os.path.join(path_dataset, '{}.pt'.format(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(path):\n",
    "    d = torch.load(path)\n",
    "    d_tr = (d[0], d[1])\n",
    "    d_te = (d[2], d[3])\n",
    "    if dataset == 'cifar100':\n",
    "        n_outputs = 100\n",
    "    else:\n",
    "        n_outputs = 10        \n",
    "    return d_tr, d_te, n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tr, d_te, n_outputs = load_datasets(os.path.join(path_dataset, '{}.pt'.format(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR(torch.utils.data.Dataset):\n",
    "    def __init__(self, pack, method, train=False):\n",
    "        self.x = pack[0]\n",
    "        self.y = pack[1]\n",
    "        self.img_size = (3,32,32)\n",
    "        \n",
    "        self.method = method\n",
    "        self.train = train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def transform(self, img):\n",
    "        top = torch.randint(0,8,(1,))\n",
    "        left = torch.randint(0,8,(1,))\n",
    "        img = TF.crop(img, top=top, left=left, height=self.img_size[1], width=self.img_size[2])\n",
    "        \n",
    "        if torch.rand(1) > 0.5:\n",
    "            img = TF.hflip(img)\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        x = self.x[item].float() / 255.0\n",
    "        \n",
    "        x = x.permute(2,0,1)\n",
    "        \n",
    "        if self.train:\n",
    "            x = TF.pad(x, padding=4)\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        if 'bcplus' not in self.method:\n",
    "            mean_image = torch.from_numpy(np.array([0.4914, 0.4822, 0.4465])).float()\n",
    "            std_image = torch.from_numpy(np.array([0.2023, 0.1994, 0.2010])).float()\n",
    "        else:\n",
    "            x = x - torch.mean(x)\n",
    "            mean_image = torch.from_numpy(np.array([0.21921569, 0.21058824, 0.22156863])).float()\n",
    "            std_image = torch.from_numpy(np.array([0.2023, 0.1994, 0.2010])).float()\n",
    "        \n",
    "        x = x.permute(1,2,0)\n",
    "        x = x - mean_image\n",
    "        x = x / std_image\n",
    "        \n",
    "        return x.permute(2,0,1), self.y[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = CIFAR(d_tr, method, train=True)\n",
    "train_dataloaders = torch.utils.data.DataLoader(train_datasets, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = CIFAR(d_te, method)\n",
    "test_dataloaders = torch.utils.data.DataLoader(test_datasets, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_datasets), len(test_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataloaders), len(test_dataloaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(train_dataloaders):\n",
    "    mean_image = torch.from_numpy(np.array([0.4914, 0.4822, 0.4465])).float()\n",
    "    std_image = torch.from_numpy(np.array([0.2023, 0.1994, 0.2010])).float()\n",
    "    img = d[0].permute(0,2,3,1) * std_image + mean_image\n",
    "    save_image(img.permute(0,3,1,2), './tmp.png')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verticalConcatMask(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    lambda_vertical_beta = beta.Beta(torch.tensor([1.]), torch.tensor([1.]))\n",
    "    lambda_vertical = lambda_vertical_beta.sample(torch.Size([b])).view(b,1)\n",
    "    \n",
    "    img_1, label_1 = batch_1[0], batch_1[1]\n",
    "    img_2, label_2 = batch_2[0], batch_2[1]\n",
    "    \n",
    "    if len(label_1.shape) == 1:\n",
    "        label_1 = F.one_hot(label_1, num_classes=n_outputs)\n",
    "        \n",
    "    if len(label_2.shape) == 1:\n",
    "        label_2 = F.one_hot(label_2, num_classes=n_outputs)\n",
    "    \n",
    "    binary_mask = torch.ones(img_1.shape)\n",
    "    for b_indx in range(b):\n",
    "        binary_mask[b_indx,:,(lambda_vertical[b_indx]*h).long():,:] = 0\n",
    "        \n",
    "    vertical_img = binary_mask * img_1 + (1 - binary_mask) * img_2\n",
    "    vertical_label = (lambda_vertical*h).long().repeat(1,n_outputs) / h * label_1 + \\\n",
    "                        (h - (lambda_vertical*h).long()).repeat(1,n_outputs) / h * label_2\n",
    "    \n",
    "    return vertical_img, vertical_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontalConcatMask(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    lambda_horizontal_beta = beta.Beta(torch.tensor([1.]), torch.tensor([1.]))\n",
    "    lambda_horizontal = lambda_horizontal_beta.sample(torch.Size([b])).view(b,1)\n",
    "    \n",
    "    img_1, label_1 = batch_1[0], batch_1[1]\n",
    "    img_2, label_2 = batch_2[0], batch_2[1]\n",
    "    \n",
    "    if len(label_1.shape) == 1:\n",
    "        label_1 = F.one_hot(label_1, num_classes=n_outputs)\n",
    "        \n",
    "    if len(label_2.shape) == 1:\n",
    "        label_2 = F.one_hot(label_2, num_classes=n_outputs)\n",
    "    \n",
    "    binary_mask = torch.ones(img_1.shape)\n",
    "    for b_indx in range(b):\n",
    "        binary_mask[b_indx,:,:,(lambda_horizontal[b_indx]*w).long():] = 0\n",
    "        \n",
    "    horizontal_img = binary_mask * img_1 + (1 - binary_mask) * img_2\n",
    "    horizontal_label = (lambda_horizontal*w).long().repeat(1,n_outputs) / w * label_1 + \\\n",
    "                        (w - (lambda_horizontal*w).long()).repeat(1,n_outputs) / w * label_2\n",
    "    \n",
    "    return horizontal_img, horizontal_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VHMixup(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    lambda_mixup_beta = beta.Beta(torch.tensor([1.]), torch.tensor([1.]))\n",
    "    lambda_mixup = lambda_mixup_beta.sample(torch.Size([b])).view(b,1)\n",
    "    \n",
    "    vertical_concat, vertical_label = verticalConcatMask(batch_1, batch_2)\n",
    "    horizontal_concat, horizontal_label = horizontalConcatMask(batch_1, batch_2)\n",
    "    \n",
    "    mixed_img = lambda_mixup.reshape(b,1,1,1).repeat(1,c,h,w) * vertical_concat + \\\n",
    "                    (1 - lambda_mixup.reshape(b,1,1,1).repeat(1,c,h,w)) * horizontal_concat\n",
    "    mixed_label = lambda_mixup.repeat(1,n_outputs) * vertical_label + \\\n",
    "                    (1 - lambda_mixup.repeat(1,n_outputs)) * horizontal_label\n",
    "    \n",
    "    return mixed_img, mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VHBCplus(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    vertical_concat, vertical_label = verticalConcatMask(batch_1, batch_2)\n",
    "    horizontal_concat, horizontal_label = horizontalConcatMask(batch_1, batch_2)\n",
    "    \n",
    "    lambda_uni = torch.rand(b)\n",
    "    lambda_factor = (1 - lambda_uni) / lambda_uni\n",
    "    \n",
    "    vertical_std = torch.std(vertical_concat.view(b,-1),dim=1)\n",
    "    horizontal_std = torch.std(horizontal_concat.view(b,-1),dim=1)\n",
    "    std_factor = vertical_std / horizontal_std\n",
    "\n",
    "    p = 1 / (1 + std_factor * lambda_factor)\n",
    "    \n",
    "    denom = torch.sqrt(p**2 + (1-p)**2)\n",
    "    \n",
    "    c, h, w = batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    bcplus_img = (p.reshape(b,1,1,1).repeat(1,c,h,w) * vertical_concat + \\\n",
    "                      (1 - p).reshape(b,1,1,1).repeat(1,c,h,w) * horizontal_concat) / denom.reshape(b,1,1,1).repeat(1,c,h,w)\n",
    "    bcplus_label = lambda_uni.reshape(b,1).repeat(1,n_outputs) * vertical_label + \\\n",
    "                        (1 - lambda_uni.reshape(b,1).repeat(1,n_outputs)) * horizontal_label\n",
    "    \n",
    "    return bcplus_img, bcplus_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes, nf):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = nf\n",
    "\n",
    "        self.conv1 = conv3x3(3, nf * 1)\n",
    "        self.bn1 = nn.BatchNorm2d(nf * 1)\n",
    "        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(nf * 8 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz = x.size(0)\n",
    "        out = relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(nclasses, nf=64):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], nclasses, nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = './Results/'\n",
    "now =  '{}_ResNet_{}_{}'.format(dataset, method, seed)\n",
    "\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    os.makedirs(ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(ROOT_DIR + now):\n",
    "    os.makedirs(ROOT_DIR + now)\n",
    "\n",
    "LOG_DIR = ROOT_DIR + now + '/logs/'\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "else:\n",
    "    import shutil\n",
    "    shutil.rmtree(LOG_DIR)\n",
    "    os.makedirs(LOG_DIR)\n",
    "    \n",
    "MODEL_DIR = ROOT_DIR + now + '/models/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "summary_writer = SummaryWriter(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(n_outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'vhmixup':\n",
    "    augmentor = VHMixup\n",
    "else:\n",
    "    augmentor = VHBCplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimizer and Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler_1 = torch.optim.lr_scheduler.MultiStepLR(opt, gamma=lr_scheduler_1_gamma, milestones=milestones_1)\n",
    "scheduler_2 = torch.optim.lr_scheduler.MultiStepLR(opt, gamma=lr_scheduler_2_gamma, milestones=milestones_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softXEnt(output, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(output, dim = 1)\n",
    "        return  -(target * logprobs).sum() / output.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(train_epochs+1):\n",
    "    model.train()\n",
    "    for i, d in enumerate(tqdm.tqdm(train_dataloaders)):\n",
    "        indx = torch.randperm(d[0].shape[0])\n",
    "        x1, y1 = d[0], d[1]\n",
    "        x2, y2 = x1[indx], y1[indx]\n",
    "\n",
    "        x, y = augmentor((x1,y1), (x2,y2))\n",
    "        \n",
    "        x = x.float().to(device)\n",
    "        y = y.float().to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        out = model(x)\n",
    "        \n",
    "        loss = softXEnt(out, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        summary_writer.add_scalar('Loss', loss.item())\n",
    "        \n",
    "        # Scheduler is defined based on total number of iterations\n",
    "        scheduler_1.step()\n",
    "        scheduler_2.step()\n",
    "        \n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    for i, d in enumerate(test_dataloaders):\n",
    "        x, y = d[0], d[1]\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out_prob = model(x)\n",
    "        \n",
    "        pred = torch.argmax(out_prob, dim=1)\n",
    "        prediction = pred.cpu().numpy()\n",
    "        truth = y.cpu().numpy()\n",
    "        acc = np.count_nonzero(prediction == truth)\n",
    "\n",
    "        total_acc += acc\n",
    "        \n",
    "    print('After the accuracy after {} epochs is {}'.format(epoch, total_acc / len(test_datasets)))\n",
    "    print()\n",
    "\n",
    "    summary_writer.add_scalar('Eval ACC', total_acc / len(test_datasets))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), MODEL_DIR+'epoch_{}.pth'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc / len(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_DIR+'final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_acc = 0\n",
    "for i, d in enumerate(test_dataloaders):\n",
    "    x, y = d[0], d[1]\n",
    "    x = x.float().to(device)\n",
    "    y = y.long().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_prob = model(x)\n",
    "\n",
    "    pred = torch.argmax(out_prob, dim=1)\n",
    "    prediction = pred.cpu().numpy()\n",
    "    truth = y.cpu().numpy()\n",
    "    acc = np.count_nonzero(prediction == truth)\n",
    "\n",
    "    total_acc += acc\n",
    "\n",
    "print('After the accuracy after {} epochs is {}'.format(epoch, total_acc / len(test_datasets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
