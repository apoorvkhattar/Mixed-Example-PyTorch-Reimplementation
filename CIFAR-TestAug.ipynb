{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions.beta as beta\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn.functional import relu, avg_pool2d\n",
    "from sklearn.calibration import calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Preparation Arguments'''\n",
    "data_prep_from_scratch = True\n",
    "dataset = 'cifar10'\n",
    "path_dataset = './Data/CIFAR10/'\n",
    "\n",
    "'''Data Augmentation Method'''\n",
    "method = 'vhmixup'\n",
    "\n",
    "'''Optimization Arguments'''\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_prep_from_scratch and dataset == 'cifar100':\n",
    "    cifar100_train = unpickle(os.path.join(path_dataset, 'train'))\n",
    "    cifar100_test = unpickle(os.path.join(path_dataset, 'test'))\n",
    "\n",
    "    x_tr = torch.from_numpy(cifar100_train[b'data'].reshape((-1,32,32,3), order='F')).permute(0,2,1,3)\n",
    "    y_tr = torch.LongTensor(cifar100_train[b'fine_labels'])\n",
    "    x_te = torch.from_numpy(cifar100_test[b'data'].reshape((-1,32,32,3), order='F')).permute(0,2,1,3)\n",
    "    y_te = torch.LongTensor(cifar100_test[b'fine_labels'])\n",
    "\n",
    "    torch.save((x_tr, y_tr, x_te, y_te), os.path.join(path_dataset, '{}.pt'.format(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_prep_from_scratch and dataset == 'cifar10':\n",
    "    x_tr, y_tr = None, None\n",
    "    for b in range(5):\n",
    "        cifar10_train = unpickle(os.path.join(path_dataset, 'data_batch_{}'.format(b+1)))\n",
    "        \n",
    "        batch_img = torch.from_numpy(cifar10_train[b'data'].reshape((-1,32,32,3), order='F')).permute(0,2,1,3)\n",
    "        batch_label = torch.LongTensor(cifar10_train[b'labels'])\n",
    "        \n",
    "        if x_tr is None:\n",
    "            x_tr = batch_img\n",
    "            y_tr = batch_label\n",
    "        else:\n",
    "            x_tr = torch.cat((x_tr, batch_img), dim=0)\n",
    "            y_tr = torch.cat((y_tr, batch_label), dim=0)\n",
    "    \n",
    "    cifar10_test = unpickle(os.path.join(path_dataset, 'test_batch'))\n",
    "    x_te = torch.from_numpy(cifar10_test[b'data'].reshape((-1,32,32,3), order='F')).permute(0,2,1,3)\n",
    "    y_te = torch.LongTensor(cifar10_test[b'labels'])\n",
    "    \n",
    "    torch.save((x_tr, y_tr, x_te, y_te), os.path.join(path_dataset, '{}.pt'.format(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(path):\n",
    "    d = torch.load(path)\n",
    "    d_tr = (d[0], d[1])\n",
    "    d_te = (d[2], d[3])\n",
    "    if dataset == 'cifar100':\n",
    "        n_outputs = 100\n",
    "    else:\n",
    "        n_outputs = 10        \n",
    "    return d_tr, d_te, n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tr, d_te, n_outputs = load_datasets(os.path.join(path_dataset, '{}.pt'.format(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR(torch.utils.data.Dataset):\n",
    "    def __init__(self, pack, method, train=False):\n",
    "        self.x = pack[0]\n",
    "        self.y = pack[1]\n",
    "        self.img_size = (3,32,32)\n",
    "        \n",
    "        self.method = method\n",
    "        self.train = train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def transform(self, img):\n",
    "        top = torch.randint(0,8,(1,))\n",
    "        left = torch.randint(0,8,(1,))\n",
    "        img = TF.crop(img, top=top, left=left, height=self.img_size[1], width=self.img_size[2])\n",
    "        \n",
    "        if torch.rand(1) > 0.5:\n",
    "            img = TF.hflip(img)\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        x = self.x[item].float() / 255.0\n",
    "        \n",
    "        x = x.permute(2,0,1)\n",
    "        \n",
    "        if self.train:\n",
    "            x = TF.pad(x, padding=4)\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        if 'bcplus' not in self.method:\n",
    "            mean_image = torch.from_numpy(np.array([0.4914, 0.4822, 0.4465])).float()\n",
    "            std_image = torch.from_numpy(np.array([0.2023, 0.1994, 0.2010])).float()\n",
    "        else:\n",
    "            x = x - torch.mean(x)\n",
    "            mean_image = torch.from_numpy(np.array([0.21921569, 0.21058824, 0.22156863])).float()\n",
    "            std_image = torch.from_numpy(np.array([0.2023, 0.1994, 0.2010])).float()\n",
    "        \n",
    "        x = x.permute(1,2,0)\n",
    "        x = x - mean_image\n",
    "        x = x / std_image\n",
    "        \n",
    "        return x.permute(2,0,1), self.y[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = CIFAR(d_te, method)\n",
    "test_dataloaders = torch.utils.data.DataLoader(test_datasets, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataloaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(test_dataloaders):\n",
    "    mean_image = torch.from_numpy(np.array([0.4914, 0.4822, 0.4465])).float()\n",
    "    std_image = torch.from_numpy(np.array([0.2023, 0.1994, 0.2010])).float()\n",
    "    img = d[0].permute(0,2,3,1) * std_image + mean_image\n",
    "    save_image(img.permute(0,3,1,2), './tmp.png')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verticalConcatMask(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    lambda_vertical_beta = beta.Beta(torch.tensor([1.]), torch.tensor([1.]))\n",
    "    lambda_vertical = lambda_vertical_beta.sample(torch.Size([b])).view(b,1)\n",
    "    \n",
    "    img_1, label_1 = batch_1[0], batch_1[1]\n",
    "    img_2, label_2 = batch_2[0], batch_2[1]\n",
    "    \n",
    "    if len(label_1.shape) == 1:\n",
    "        label_1 = F.one_hot(label_1, num_classes=n_outputs)\n",
    "        \n",
    "    if len(label_2.shape) == 1:\n",
    "        label_2 = F.one_hot(label_2, num_classes=n_outputs)\n",
    "    \n",
    "    binary_mask = torch.ones(img_1.shape)\n",
    "    for b_indx in range(b):\n",
    "        binary_mask[b_indx,:,(lambda_vertical[b_indx]*h).long():,:] = 0\n",
    "        \n",
    "    vertical_img = binary_mask * img_1 + (1 - binary_mask) * img_2\n",
    "    vertical_label = (lambda_vertical*h).long().repeat(1,n_outputs) / h * label_1 + \\\n",
    "                        (h - (lambda_vertical*h).long()).repeat(1,n_outputs) / h * label_2\n",
    "    \n",
    "    return vertical_img, vertical_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontalConcatMask(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    lambda_horizontal_beta = beta.Beta(torch.tensor([1.]), torch.tensor([1.]))\n",
    "    lambda_horizontal = lambda_horizontal_beta.sample(torch.Size([b])).view(b,1)\n",
    "    \n",
    "    img_1, label_1 = batch_1[0], batch_1[1]\n",
    "    img_2, label_2 = batch_2[0], batch_2[1]\n",
    "    \n",
    "    if len(label_1.shape) == 1:\n",
    "        label_1 = F.one_hot(label_1, num_classes=n_outputs)\n",
    "        \n",
    "    if len(label_2.shape) == 1:\n",
    "        label_2 = F.one_hot(label_2, num_classes=n_outputs)\n",
    "    \n",
    "    binary_mask = torch.ones(img_1.shape)\n",
    "    for b_indx in range(b):\n",
    "        binary_mask[b_indx,:,:,(lambda_horizontal[b_indx]*w).long():] = 0\n",
    "        \n",
    "    horizontal_img = binary_mask * img_1 + (1 - binary_mask) * img_2\n",
    "    horizontal_label = (lambda_horizontal*w).long().repeat(1,n_outputs) / w * label_1 + \\\n",
    "                        (w - (lambda_horizontal*w).long()).repeat(1,n_outputs) / w * label_2\n",
    "    \n",
    "    return horizontal_img, horizontal_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mixup(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    lambda_mixup_beta = beta.Beta(torch.tensor([1.]), torch.tensor([1.]))\n",
    "    lambda_mixup = lambda_mixup_beta.sample(torch.Size([b])).view(b,1)\n",
    "    \n",
    "    img_1, label_1 = batch_1[0], batch_1[1]\n",
    "    img_2, label_2 = batch_2[0], batch_2[1]\n",
    "    \n",
    "    if len(label_1.shape) == 1:\n",
    "        label_1 = F.one_hot(label_1, num_classes=n_outputs)\n",
    "        \n",
    "    if len(label_2.shape) == 1:\n",
    "        label_2 = F.one_hot(label_2, num_classes=n_outputs)\n",
    "    \n",
    "    mixed_img = lambda_mixup.reshape(b,1,1,1).repeat(1,c,h,w) * img_1 + \\\n",
    "                    (1 - lambda_mixup.reshape(b,1,1,1).repeat(1,c,h,w)) * img_2\n",
    "    mixed_label = lambda_mixup.repeat(1,n_outputs) * label_1 + \\\n",
    "                    (1 - lambda_mixup.repeat(1,n_outputs)) * label_2\n",
    "    \n",
    "    return mixed_img, mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VHMixup(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    lambda_mixup_beta = beta.Beta(torch.tensor([1.]), torch.tensor([1.]))\n",
    "    lambda_mixup = lambda_mixup_beta.sample(torch.Size([b])).view(b,1)\n",
    "    \n",
    "    vertical_concat, vertical_label = verticalConcatMask(batch_1, batch_2)\n",
    "    horizontal_concat, horizontal_label = horizontalConcatMask(batch_1, batch_2)\n",
    "    \n",
    "    mixed_img = lambda_mixup.reshape(b,1,1,1).repeat(1,c,h,w) * vertical_concat + \\\n",
    "                    (1 - lambda_mixup.reshape(b,1,1,1).repeat(1,c,h,w)) * horizontal_concat\n",
    "    mixed_label = lambda_mixup.repeat(1,n_outputs) * vertical_label + \\\n",
    "                    (1 - lambda_mixup.repeat(1,n_outputs)) * horizontal_label\n",
    "    \n",
    "    return mixed_img, mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VHBCplus(batch_1, batch_2):\n",
    "    b, c, h, w = batch_1[0].shape[0], batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    vertical_concat, vertical_label = verticalConcatMask(batch_1, batch_2)\n",
    "    horizontal_concat, horizontal_label = horizontalConcatMask(batch_1, batch_2)\n",
    "    \n",
    "    lambda_uni = torch.rand(b)\n",
    "    lambda_factor = (1 - lambda_uni) / lambda_uni\n",
    "    \n",
    "    vertical_std = torch.std(vertical_concat.view(b,-1),dim=1)\n",
    "    horizontal_std = torch.std(horizontal_concat.view(b,-1),dim=1)\n",
    "    std_factor = vertical_std / horizontal_std\n",
    "\n",
    "    p = 1 / (1 + std_factor * lambda_factor)\n",
    "    \n",
    "    denom = torch.sqrt(p**2 + (1-p)**2)\n",
    "    \n",
    "    c, h, w = batch_1[0].shape[1], batch_1[0].shape[2], batch_1[0].shape[3]\n",
    "    \n",
    "    bcplus_img = (p.reshape(b,1,1,1).repeat(1,c,h,w) * vertical_concat + \\\n",
    "                      (1 - p).reshape(b,1,1,1).repeat(1,c,h,w) * horizontal_concat) / denom.reshape(b,1,1,1).repeat(1,c,h,w)\n",
    "    bcplus_label = lambda_uni.reshape(b,1).repeat(1,n_outputs) * vertical_label + \\\n",
    "                        (1 - lambda_uni.reshape(b,1).repeat(1,n_outputs)) * horizontal_label\n",
    "    \n",
    "    return bcplus_img, bcplus_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes, nf):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = nf\n",
    "\n",
    "        self.conv1 = conv3x3(3, nf * 1)\n",
    "        self.bn1 = nn.BatchNorm2d(nf * 1)\n",
    "        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(nf * 8 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz = x.size(0)\n",
    "        out = relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(nclasses, nf=64):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], nclasses, nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18(n_outputs).to(device)\n",
    "model.load_state_dict(torch.load('./Results/cidar10_ResNet_baseline/models/final.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = VHMixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bins(preds):\n",
    "    # Assign each prediction to a bin\n",
    "    num_bins = 100\n",
    "    bins = np.linspace(0.1, 1, num_bins)\n",
    "    binned = np.digitize(preds, bins)\n",
    "\n",
    "    # Save the accuracy, confidence and size of each bin\n",
    "    bin_accs = np.zeros(num_bins)\n",
    "    bin_confs = np.zeros(num_bins)\n",
    "    bin_sizes = np.zeros(num_bins)\n",
    "    \n",
    "    for bin in range(num_bins):\n",
    "        bin_sizes[bin] = len(preds[binned == bin])\n",
    "        if bin_sizes[bin] > 0:\n",
    "            bin_accs[bin] = (labels_oneh[binned==bin]).sum() / bin_sizes[bin]\n",
    "            bin_confs[bin] = (preds[binned==bin]).sum() / bin_sizes[bin]\n",
    "\n",
    "    return bins, binned, bin_accs, bin_confs, bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(preds):\n",
    "    ECE = 0\n",
    "    MCE = 0\n",
    "    bins, _, bin_accs, bin_confs, bin_sizes = calc_bins(preds)\n",
    "\n",
    "    for i in range(len(bins)):\n",
    "        abs_conf_dif = abs(bin_accs[i] - bin_confs[i])\n",
    "        ECE += (bin_sizes[i] / sum(bin_sizes)) * abs_conf_dif\n",
    "        MCE = max(MCE, abs_conf_dif)\n",
    "\n",
    "    return ECE, MCE, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softXEnt(output, target):\n",
    "    logprobs = torch.nn.functional.log_softmax(output, dim = 1)\n",
    "    return  -(target * logprobs).sum() / output.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:15<00:00,  5.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_probs = None\n",
    "labels_oneh = None\n",
    "\n",
    "for i, d in enumerate(tqdm.tqdm(test_dataloaders)):\n",
    "    x, y = d[0], d[1]\n",
    "\n",
    "    x = x.float().to(device)\n",
    "    y = y.long().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_prob = F.softmax(model(x), dim=1).cpu().numpy()\n",
    "    \n",
    "    if pred_probs is None:\n",
    "        pred_probs = out_prob\n",
    "    else:\n",
    "        pred_probs = np.concatenate((pred_probs, out_prob), axis=0)\n",
    "        \n",
    "    if labels_oneh is None:\n",
    "        labels_oneh = F.one_hot(y, num_classes=10).cpu().numpy()\n",
    "    else:\n",
    "        labels_oneh = np.concatenate((labels_oneh, F.one_hot(y, num_classes=10).cpu().numpy()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = pred_probs.flatten()\n",
    "labels_oneh = labels_oneh.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ece, mce, binned = get_metrics(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006550298200845712"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "total_acc = 0; atleast_one_acc = 0; prime_acc = 0\n",
    "for i, d in enumerate(tqdm.tqdm(test_dataloaders)):\n",
    "    indx = torch.randperm(d[0].shape[0])\n",
    "    x1, y1 = d[0], d[1]\n",
    "    x2, y2 = x1[indx], y1[indx]\n",
    "\n",
    "    x, y = augmentor((x1,y1), (x2,y2))\n",
    "\n",
    "    x = x.float().to(device)\n",
    "    y = y.float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_prob = model(x)\n",
    "        loss = softXEnt(out_prob, y)\n",
    "                \n",
    "    out_labels = torch.topk(out_prob, 2, dim=1)[1]\n",
    "    out_l1 = out_labels[:,0]; out_l2 = out_labels[:,1]\n",
    "    \n",
    "    pred_labels = torch.topk(y, 2, dim=1)[1]\n",
    "    pred_l1 = pred_labels[:,0]; pred_l2 = pred_labels[:,1]\n",
    "    \n",
    "    prediction = out_l1.cpu().numpy()\n",
    "    truth = pred_l1.cpu().numpy()\n",
    "    acc_l1 = prediction == truth\n",
    "        \n",
    "    prediction = out_l2.cpu().numpy()\n",
    "    truth = pred_l2.cpu().numpy()\n",
    "    acc_l2 = prediction == truth\n",
    "    \n",
    "    primary_label = y1.cpu().numpy()\n",
    "    acc_prime_1 = out_l1.cpu().numpy() == primary_label\n",
    "    acc_prime_2 = out_l2.cpu().numpy() == primary_label\n",
    "    \n",
    "    acc_prime = np.count_nonzero(acc_prime_1 | acc_prime_2)\n",
    "    prime_acc += acc_prime\n",
    "    \n",
    "    one_acc = np.count_nonzero(acc_l1 | acc_l2)\n",
    "    atleast_one_acc += one_acc\n",
    "    \n",
    "    both_acc = np.count_nonzero(acc_l1 & acc_l2)\n",
    "    total_acc += both_acc\n",
    "    \n",
    "    total_loss += loss.item()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_acc / len(test_datasets), atleast_one_acc / len(test_datasets), total_loss / len(test_datasets), prime_acc / len(test_datasets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
